{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolobiancalana/crypto-trading-bot-rl/blob/main/Crypto_Trading_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 - Install Dependencies"
      ],
      "metadata": {
        "id": "uglCgVhsWiV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psxbLRsqWSlx",
        "outputId": "7eba81c3-05c6-41b3-eaee-07e3b598b54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alpaca-py\n",
            "  Downloading alpaca_py-0.8.2-py3-none-any.whl (96 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/96.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from alpaca-py) (1.0.5)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from alpaca-py) (1.5.3)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from alpaca-py) (1.10.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from alpaca-py) (2.27.1)\n",
            "Collecting sseclient-py<2.0.0,>=1.7.2 (from alpaca-py)\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting websockets<11.0,>=10.2 (from alpaca-py)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->alpaca-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->alpaca-py) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->alpaca-py) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.9.0->alpaca-py) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->alpaca-py) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->alpaca-py) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->alpaca-py) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.27.1->alpaca-py) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.3.5->alpaca-py) (1.16.0)\n",
            "Installing collected packages: sseclient-py, websockets, alpaca-py\n",
            "Successfully installed alpaca-py-0.8.2 sseclient-py-1.7.2 websockets-10.4\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.7/323.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'aiohttp' candidate (version 3.8.2 at https://files.pythonhosted.org/packages/8f/52/ea1e5eac3e748a94fdaafba5ab68adfb833f0cbdb68cc8149fbba5574176/aiohttp-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/aiohttp/) (requires-python:>=3.6))\n",
            "Reason for being yanked: This version includes overly restrictive multidict upper boundary disallowing multidict v6+. The previous patch version didn't have that and this is now causing dependency resolution problems for the users who have an \"incompatible\" version pinned. This is not really necessary anymore and will be addressed in the next release v3.8.3\n",
            "\n",
            "https://github.com/aio-libs/aiohttp/pull/6950\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pycoingecko\n",
            "  Downloading pycoingecko-3.1.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pycoingecko) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pycoingecko) (3.4)\n",
            "Installing collected packages: pycoingecko\n",
            "Successfully installed pycoingecko-3.1.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<6.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (5.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-zrpxrwq6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git /tmp/pip-req-build-zrpxrwq6\n",
            "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit 614d4c2029a62d348ca56598f87c425966aaec66\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (2.27.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (3.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->snscrape==0.7.0.20230622) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.7.1)\n",
            "Building wheels for collected packages: snscrape\n",
            "  Building wheel for snscrape (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for snscrape: filename=snscrape-0.7.0.20230622-py3-none-any.whl size=74814 sha256=85cf666e8a1e86fba598782616c7591841b05f2cb7c4bc7915e61622e1e234be\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6wr3uvg8/wheels/05/e9/f7/57056e7c7e44b1feed932fa49fdec9d706c4f563e37160ab74\n",
            "Successfully built snscrape\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.7.0.20230622\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (6.0)\n",
            "Collecting loguru>=0.5.0 (from pinecone-client)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.6.3)\n",
            "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.26.16)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
            "Installing collected packages: loguru, dnspython, pinecone-client\n",
            "Successfully installed dnspython-2.3.0 loguru-0.7.0 pinecone-client-2.2.2\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.219-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk>=0.0.17 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.17-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (5.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiohttp, dataclasses-json, langchain\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.8.2\n",
            "    Uninstalling aiohttp-3.8.2:\n",
            "      Successfully uninstalled aiohttp-3.8.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "alpaca-trade-api 3.0.2 requires aiohttp==3.8.2, but you have aiohttp 3.8.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 dataclasses-json-0.5.8 langchain-0.0.219 langchainplus-sdk-0.0.17 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install alpaca-py\n",
        "!pip install -q alpaca-trade-api\n",
        "!pip install pycoingecko\n",
        "!pip install requests\n",
        "!pip install openai\n",
        "!pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "!pip install pinecone-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - Import Data"
      ],
      "metadata": {
        "id": "bgYxuB8pWvQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pycoingecko import CoinGeckoAPI\n",
        "import requests\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "import datetime as dt\n",
        "import openai\n",
        "import alpaca_trade_api as tradeapi\n",
        "from alpaca_trade_api.rest import TimeFrame\n",
        "import re\n",
        "import time\n",
        "import pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csnX63HhWwyR",
        "outputId": "0912ba4d-4ead-4712-e323-a70a74d5f150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Source 1/4: Price History"
      ],
      "metadata": {
        "id": "0ten_EZPW_cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cg = CoinGeckoAPI()\n",
        "\n",
        "cryptos = ['chainlink', 'ethereum', 'matic-network', 'solana', 'presearch']\n",
        "\n",
        "crypto_data = ''\n",
        "\n",
        "for crypto in cryptos:\n",
        "    data = cg.get_coin_market_chart_by_id(crypto, vs_currency='usd', days=30)\n",
        "    prices = data['prices']\n",
        "    prices_only = [price[1] for price in prices]\n",
        "    high = max(prices_only)\n",
        "    low = min(prices_only)\n",
        "    avg = np.mean(prices_only)\n",
        "    crypto_data+=f\" {crypto} data for the past 30 days: High={high}, Low={low}, Average={avg}\"\n",
        "    print(f\"{crypto} data for the past 30 days: High={high}, Low={low}, Average={avg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAwiRkHeW8kT",
        "outputId": "d80e3bc4-7491-4ce9-84b5-591d4b0cea7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bitcoin data for the past 30 days: High=31185.219831413775, Low=24864.608901885007, Average=27555.093029453637\n",
            "ethereum data for the past 30 days: High=1922.831648666678, Low=1632.457370596918, Average=1818.1107357196472\n",
            "matic-network data for the past 30 days: High=0.9087424514904233, Low=0.5579180724197483, Average=0.7090857588377285\n",
            "solana data for the past 30 days: High=22.23048506493996, Low=13.805519170106006, Average=17.48240568534618\n",
            "avalanche-2 data for the past 30 days: High=14.905311045572896, Low=10.754774467001235, Average=12.90989605113597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Source 3/4: News Sentiment"
      ],
      "metadata": {
        "id": "r8TgziWYXJgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = [\"LINK\", \"ETH\", \"PRE\", \"SOL\", \"PRE\"]\n",
        "\n",
        "def get_all_crypto_news():\n",
        "    API_KEY = \"ENTER YOUR KEY\"\n",
        "    all_news = {}\n",
        "\n",
        "    for symbol in symbols:\n",
        "        url = f'https://newsapi.org/v2/everything?q={symbol}&apiKey={API_KEY}'\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "\n",
        "        news_data = []\n",
        "        try:\n",
        "            for article in data['articles'][:3]:  # Limit to top 3 articles\n",
        "                news_data.append({\n",
        "                    'title': article['title'],\n",
        "                    'source': article['source']['name'],\n",
        "                })\n",
        "            all_news[symbol] = news_data\n",
        "        except:\n",
        "            return all_news\n",
        "\n",
        "    return all_news\n",
        "\n",
        "news_output = get_all_crypto_news()\n",
        "print(textwrap.fill(str(news_output), width=50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buaUMuLHXOZd",
        "outputId": "e406b5e8-8fcc-472d-d456-bbc1e969b549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'BTC': [{'title': 'DOJ charges Russian nationals\n",
            "with laundering bitcoin in 2011 Mt. Gox hack',\n",
            "'source': 'Engadget'}, {'title': 'Altcoins:\n",
            "Exploring the Best Cryptocurrencies Beyond BTC',\n",
            "'source': 'ReadWrite'}, {'title': '9 Years After\n",
            "the Mt. Gox Hack, Feds Indict Alleged Culprits',\n",
            "'source': 'Wired'}], 'ETH': [{'title': 'Apollo\n",
            "Back end just made public', 'source': 'Reddit\n",
            "/r/all'}, {'title': 'Los dentistas se han topado\n",
            "con un enemigo inesperado: los propios dentistas y\n",
            "los tratamientos innecesarios', 'source':\n",
            "'Xataka.com'}, {'title': 'The mystery of our\n",
            "transparent universe has been solved!', 'source':\n",
            "'Yahoo Entertainment'}], 'MATIC': [{'title':\n",
            "'Coinbase and Binance Lawsuits Put Crypto on Ice',\n",
            "'source': 'Wired'}, {'title': 'Dogecoin and\n",
            "Polygon Price Prediction and Beyond: a Look at Key\n",
            "Altcoins for 2023', 'source': 'Due.com'},\n",
            "{'title': 'Robinhood App Will End Support for\n",
            "Three Cryptocurrency Tokens After June 27',\n",
            "'source': 'Slashdot.org'}], 'SOL': [{'title': 'Sol\n",
            "Reader Is a VR Headset Exclusively For Reading\n",
            "Books', 'source': 'Slashdot.org'}, {'title':\n",
            "'Coinbase and Binance Lawsuits Put Crypto on Ice',\n",
            "'source': 'Wired'}, {'title': 'Finally! An\n",
            "e-reader for people who hate holding a book',\n",
            "'source': 'Boing Boing'}], 'AVAX': [{'title':\n",
            "'Dogecoin and Polygon Price Prediction and Beyond:\n",
            "a Look at Key Altcoins for 2023', 'source':\n",
            "'Due.com'}, {'title': 'Dominates the Crypto\n",
            "Market, Bullish Spree for Polygon (MATIC) And\n",
            "Avalanche (AVAX)', 'source': 'Biztoc.com'},\n",
            "{'title': 'Why AVAXâ€™s prospects look bleak despite\n",
            "a surge in addresses', 'source': 'Biztoc.com'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Source 2/4: Twitter Sentiment\n"
      ],
      "metadata": {
        "id": "tOlg1AD2XQ66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\"LINK\", \"ETH\", \"PRE\", \"SOL\", \"LTC\"]\n",
        "tweets_list = []\n",
        "\n",
        "for query in queries:\n",
        "    num = 0\n",
        "    for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "        if num == 10:\n",
        "            break\n",
        "        num += 1\n",
        "        tweets_list.append(tweet.rawContent)\n",
        "        print(tweet.rawContent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMGtNDrvXYC1",
        "outputId": "60ce5c8c-08db-4fcb-969a-d2433e0f8ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1668661582992232449-431d947176031da'\n",
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1651267064210812930-43199912e4656f2'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "652473 At the same time it happened,\n",
            "ğŸ”¥Hyped #BTCâ€¯â€¯â€¯ WL giveaway ğŸ”¥\n",
            "\n",
            "2x @AntiNFTBTCMaxis\n",
            "To Enter : \n",
            "\n",
            "1âƒ£Follow :@AntiNFTBTCMaxis , @D_C_famColab&amp;&amp; @d_cryptofamily \n",
            "\n",
            "2âƒ£ â™¥ï¸ , Retweet this post and paste your taproot address \n",
            "\n",
            "15 hrs \n",
            "\n",
            "#BTCHxRICH_Finale #btc #OrdinalsNFT #Ordinals https://t.co/r7rC7TQFYb\n",
            "ğŸ‘‡ I been holding on my wallet 233 ETHs, But this project $GPEPE will smoke pepe for sure. ğŸ”‹99 $PEPE $BOB $ROPE $LOYAL $PSALE $GMFAM $MONG $ETH $BTC $GPEPE $JESUS $BEN $RFD\n",
            "ğŸ‘‡ I just been airdrop $GPEPE as we speak, this one will do 1200X firsy day, calling it now. ğŸ”‹99 $PEPE $BOB $ROPE $LOYAL $PSALE $GMFAM $MONG $ETH $BTC $GPEPE $JESUS $BEN $RFD\n",
            "Working on converting Bitcoinâ€™s SHA256â€™s â€œpaddingâ€ into 3D.\n",
            "#Bitcoin #BTC https://t.co/tdNKKotraj\n",
            "HAVING WITHDRAWAL ISSUE DM\n",
            "#bstdcoin #bitlyx #zaifint #chainbil #batetiu #coinfusionx #exbills #hotbit #holbit #crypto #btcÂ  #recovery #scam #invest #japan #china #turkey #xrp  #echovfx #india #vauld #amzdoge #cyberdoge #iran #ukraine #Temu #ä»Šæœˆæã„ãŸçµµã‚’æ™’ãã† #Infbl #é‡ç”£å‹ãƒª https://t.co/Cd0djm6NNs\n",
            "Ready to take your profits to the next level? Join https://t.co/hYpNd61H7K and get access to exclusive pump signals!\n",
            "Join https://t.co/LznmYfdBiY\n",
            "#XTZ $OKB $AAVE #ENJ $BTC $ETH #FIL $CRV https://t.co/kfBcMT3W84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1668661582992232449-4317c347a51ca62'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ‘‡ Thank you so much for the airdrop, $GPEPE will do 700X tonight! ğŸ”‹99 $PEPE $BOB $ROPE $LOYAL $PSALE $GMFAM $MONG $ETH $BTC $GPEPE $JESUS $BEN $RFD\n",
            "@JetherBlaise Used to differentiate LGBTQIA and woke BTC holders from the old BTC holders. Old ones use BTC , woke ones use XBT\n",
            "Ahoy, degens! I just discovered a mysterious artifact on @Tabi_NFT.\n",
            "Join me on the voyagersâ€˜ expedition, where we uncover a wealth of exquisite treasures. Hop on board and let's catch the wind.  https://t.co/3xXuXJIThQ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1623744890545864704-4313dc8fb3244d3'\n",
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1666714175681224704-4314cb90ef78894'\n",
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1653510176668786689-4313fd97bfd20cf'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@MavsFilmRoom OMP\n",
            "@CryptoJoann @memecoin here\n",
            "Nice zkSync Eraâˆ drop! Fck SEC. âœ¨ @kingwar_eth @repanpeisu47409 @cosmoakar @kreeksky\n",
            "@bbykyoko @sochespilled whomst is this kyoko\n",
            "Check out this prĞµsale faster, it's the next $PEPE \n",
            "\n",
            "@fortsatos14 @AdrianMot7 @maxtradercoltd @crypto_culinar @Olasquare104 @NawShine13 @kreativOff @PhatRooster @hit_map @magnificenticus @Aleksei02021985 @Win43017521994 \n",
            "https://t.co/NJfbM0fqJe\n",
            "@BoredApeYC First move is picking the proper playlist to Forge to ğŸ¤˜\n",
            "@GeordieChris_F @NUFCThreatLevel Tbh never ever notice him for England don't watch him week out for chelsea. Maybe eth sees something that we don't time will tell\n",
            "@bayc1404 @BoredApeYC @EverydayZukini My set up\n",
            "@Pauly0x Lol youâ€™ve had all your vaccines I can tell by the way you project onto everyone else.\n",
            "1940982ğŸ˜›ğŸ˜toward perhaps of \n",
            " #éµä¹‰ #æ¹›æ±Ÿ #æ¯•èŠ‚  #éŸ©åŸ #åé˜´ #å…´å¹³ https://t.co/FgAQWNJJdM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1666213945491726340-431feaab38df132'\n",
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1672974464500350978-431fe9ccd1508f2'\n",
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1673978073371254786-4317cda08318003'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@reecefrailing ğŸ™\n",
            "@Chels_HQ Who sold Mata to United?\n",
            "Who sold cech to arsenal?\n",
            "Matic? Find another agenda to spin\n",
            "$BTC : 30542\n",
            "$ETH : 1851.71\n",
            "$ADA : 0.273662\n",
            "$SOL : 17.67\n",
            "$BNB : 233.4\n",
            "$MATIC : 0.624327\n",
            "$HIVE : 0.319477\n",
            "$PVU : 0.00481674\n",
            "$ZOON : 0.00050085\n",
            "$SLP : 0.00167964\n",
            "$AXS : 5.66\n",
            "@katrinpetau ğŸ™\n",
            "Thank you for the support @Dew_HQ ğŸ’œ\n",
            "\n",
            "Mucho Llamalove ğŸ¦™\n",
            "\n",
            "#NFT #PFP #MATIC\n",
            "Dreaming of a crypto bonanza? Make it happen at https://t.co/sSd2P2Mpos!\n",
            "Join https://t.co/2RfmWF8caL\n",
            "\n",
            "#BTC $ETH $ALGO #LTC #MATIC $MANA $SXP #ATOM https://t.co/6KJPRs77fc\n",
            "@alejoUTD Donde estÃ¡ Juan Mata, Matic, William, David Luiz, Peter Chech, Lampard? United, Arsenal y City no ganaron nada con ellos.\n",
            "Such abormination, why did she even agree to it in the first place and where are the rest of her family ğŸ¤¦ğŸ¾â€â™‚ï¸ğŸ¤¦ğŸ¾â€â™‚ï¸ jah know\n",
            "@BullishBrit the @Cre8orsNFT\n",
            "ğŸš„ #LINK and 54 Others,  ğŸŸ¢ 29 ğŸ”´ 26\n",
            "\n",
            "ğŸ‡°ğŸ‡· 43.54ì–µì›\n",
            "ğŸ‡ºğŸ‡¸ $3,725,752\n",
            "ğŸ‡¯ğŸ‡µ Â¥409,230,517\n",
            "ğŸ‡ªğŸ‡º â‚¬3,153,398\n",
            "ğŸ‡¨ğŸ‡³ 24,052,437å…ƒ\n",
            "\n",
            "ğŸ‰Upflow volume Now, Upbit(Korea)\n",
            "#LINK #BCH #BTC #MTL #SOL #EOS #MATIC #CHZ #ETH #ETC #BLUR #AAVE #MOC #FLOW #ADA #NEO #XEM #BSV #ZIL #XEC #LOOM #MASK #AXS #APT https://t.co/eKkZqfauNT\n",
            "Nunca le vi posibilidades a Lilly Tellez , me parece tan verdulera como #ANLO\n",
            "\n",
            "Que venga @edelamadrid !!!\n",
            "\n",
            "#FelizJueves Francisco CÃ©spedes AdÃ¡n Augusto MÃ©xico-QuerÃ©taro #Bloqueo Coco Levy Celaya Talina FernÃ¡ndez Cochitl Foro Sol Distrito Federal #EsClaudia #FentAMLO #FelizViernes\n",
            "@NikDraperIvey Nice to meet you, I'm Sol. Now you know two people who've played it lol\n",
            "@CursedSimpsons El pajero que estÃ¡ atrÃ¡s de esta cuenta debe ser un violÃ­n con todos los fetiches juntos\n",
            "@juansilvavar @GranhermanoCH23 48\n",
            "Quiero matesssğŸ¥¹\n",
            "Ay dios en que estaba pensando cuando me gustaba ese tipoğŸ¤¦ğŸ½â€â™€ï¸ğŸ¤¦ğŸ½â€â™€ï¸ğŸ¤¦ğŸ½â€â™€ï¸ğŸ¤¦ğŸ½â€â™€ï¸ğŸ¤¢\n",
            "BlackMirror's  \"Demon 79\" is way better than Death Note live action :)\n",
            "@VraiFDP_ @melina__sk @99__kopp @RTPI_G @crazybiquet @cestabimdr @bigcrimi @CerfiaFR MÃªme sur tes retweet de cul y a des Ã©trangers, t'est complÃ¨tement claquÃ©e au sol ğŸ˜‚ğŸ˜‚ c'est bien ce que je me disais, t'es juste soit un gros troll et je jspr pour toi, soit une grosse skizo\n",
            "La depresion que me genera caminar, pasar por casas hermosas y que tengan las persianas bajas por dios abriiii que te entre el sol hermoso\n",
            "Sol Pissguy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1657119957090553876-4310ba29de71cb5'\n",
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1433118016288526345-431f9937fe86687'\n",
            "WARNING:snscrape.modules.twitter:Skipping unrecognised entry ID: 'promoted-tweet-1664542366726799360-4316b5d4c40fd8a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@HumpedUnicorn @Wrathtank_avax I hope you rot in hell\n",
            "@DWOLFBTC Plot twist: they already have them\n",
            "@faucet_trade send AVAX tokens to 0xBb42448294E1C8e450c1F7D18c70c49F38c51d83 \n",
            "#avalanche_fuji_avax #avalanche_fuji #faucet #avax \n",
            "https://t.co/9OFKAxYWul\n",
            "@nobsfud https://t.co/qDNx8RIBGw\n",
            "WIP ğŸ—ï¸ Preparing for tomorrows FAF on @0xCampfire â€¦..\n",
            "More piece to come ğŸ¤ğŸ–¤â€¦\n",
            "\n",
            "#alwAyzCLUELESS\n",
            "#AVAX https://t.co/f5ZJNstXoK\n",
            "@discoiinfernos @Wrathtank_avax hump you\n",
            "@maislethevert @discoiinfernos @raffllrr @RIPDAOAVAX @cowncartel @ArtOnAvax @hodl_avax @Wrathtank_avax @SOPESGAL @virkkk_ @DanielxKilleen @mattxpalmieri ğŸ‘€ https://t.co/RUVCt3oDG5\n",
            "ğŸš¨ The $APE airdrop is here!\n",
            "\n",
            "Read the rules on our site:\n",
            "ğŸ”— https://t.co/vd4Blc8Scy\n",
            "\n",
            "#USDT #Ethereum #BAYC #NFTs #bitcoin $ARB $XRP #ETH #Binance Tether $PSYOP Matic #AVAX #crypto #APE #Coinbase $LTC $ADA $RNDR $BNB Polygon $FLOKI #BTC #100X #MAYC #APE Otherside $BTC #NFTSales\n",
            "@MrBigWhaleREAL $ETH and $AVAX\n",
            "@HumpedUnicorn @Wrathtank_avax Your humping unicorns are disgusting  morally bankrupt creatures and should be incarcerated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Source 4/4 - Trading History"
      ],
      "metadata": {
        "id": "aS3ABLkDefCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "api_key = \"YOUR KEY\"\n",
        "# find your environment next to the api key in pinecone console\n",
        "env = \"us-west1-gcp-free\"\n",
        "\n",
        "pinecone.init(api_key=api_key, environment=env)\n",
        "pinecone.whoami()\n",
        "\n",
        "index_name = 'trading-bot'\n",
        "\n",
        "import time\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    # if does not exist, create index\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=len(res['data'][0]['embedding']),\n",
        "        metric='cosine'\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    while not pinecone.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()\n",
        "\n",
        "query = f\"Historical data: {crypto_data}\\n News: {news_output} Twitter Data: {tweets_list}\\n\"\n",
        "\n",
        "res = openai.Embedding.create(\n",
        "    input=[query],\n",
        "    engine=\"text-embedding-ada-002\"\n",
        ")\n",
        "\n",
        "# retrieve from Pinecone\n",
        "xq = res['data'][0]['embedding']\n",
        "\n",
        "# get relevant contexts (including the questions)\n",
        "res = index.query(xq, top_k=5, include_metadata=True)\n",
        "print(res)\n",
        "\n",
        "sum_of_scores = 0.0\n",
        "\n",
        "# Get the list of matches\n",
        "matches = res['matches']\n",
        "\n",
        "biggest_id = 0\n",
        "# Iterate over the list\n",
        "for match in matches:\n",
        "    # Add the score of the current match to the sum\n",
        "      if int(match['id']) >= int(biggest_id):\n",
        "        biggest_id = match['id']\n",
        "        sum_of_scores += match['score']\n",
        "\n",
        "# Calculate the average by dividing the sum by the number of matches\n",
        "vector_delta = sum_of_scores / len(matches)\n",
        "\n",
        "print(\"Vector Delta: \", vector_delta)\n",
        "print(\"Biggest ID: \", biggest_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3jiwiZletfg",
        "outputId": "35b6de50-c399-4ea5-8e63-20c185e91952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'matches': [{'id': '5', 'score': 1.0, 'values': []},\n",
            "             {'id': '1', 'score': 0.999998271, 'values': []},\n",
            "             {'id': '6', 'score': 0.999998271, 'values': []},\n",
            "             {'id': '3', 'score': 0.999998271, 'values': []},\n",
            "             {'id': '2', 'score': 0.694373429, 'values': []}],\n",
            " 'namespace': ''}\n",
            "Vector Delta:  0.3999996542\n",
            "Biggest ID:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 - Prompt Engineering"
      ],
      "metadata": {
        "id": "hLNAy6sfW6JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_prompt = f\"\"\"\n",
        "You are in control of my crypto trading profile. You should take into consideration the factors you have to determine the best trade. Here is the info:\n",
        "\n",
        "You can execute these commands:\n",
        "\n",
        "1. buy_crypto_price(symbol, amount)\n",
        "2. buy_crypto_limit(symbol, amount, limit)\n",
        "3. sell_crypto_price(symbol, amount)\n",
        "4. sell_crypto_limit(symbol, amount, limit)\n",
        "5. do_nothing()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Use this when you don't see any necessary changes.\n",
        "\n",
        "You also have access to this data:\n",
        "\n",
        "1. Historical data\n",
        "2. News Headlines\n",
        "3. Twitter Data\n",
        "4. Vector Delta\n",
        "\n",
        "Vector delta measures how similar the last iterations market environment was to this one. it's a number between 0 and 1, where 1 is the most similar.\n",
        "\n",
        "The current date and time is {dt.datetime.today()}\n",
        "\n",
        "You are called once every 30 minutes, keep this in mind.\n",
        "\n",
        "The only cryptos you can trade are LINK, ETH, MATIC, SOL and LTC.\n",
        "\n",
        "here are the data sources:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Convert the info into a format suitable for the AI prompt\n",
        "info_str = f\"Historical data: {crypto_data}\\n News: {news_output} Twitter Data: {tweets_list}\\n Vector Delta: {vector_delta}\"\n",
        "prompt = base_prompt + \"\\n\\n\" + info_str\n",
        "user_prompt = \"\"\"\n",
        "What should we do to make the most amount of profit based on the info? Here are your options for a response.\n",
        "\n",
        "1. buy_crypto_price(symbol, amount) This will buy the specified amount of the specified cryptocurrency.\n",
        "2. buy_crypto_limit(symbol, amount, limit) This will set a limit order to buy the specified amount of the specified cryptocurrency if it reaches the specified limit.\n",
        "3. sell_crypto_price(symbol, amount) This will sell the specified amount of the specified cryptocurrency.\n",
        "4. sell_crypto_limit(symbol, amount, limit) This will set a limit order to sell the specified amount of the specified cryptocurrency if it reaches the specified limit.\n",
        "5. do_nothing() Use this when you don't see any necessary changes.\n",
        "\n",
        "Choose one.\n",
        "CRITICAL: RESPOND IN ONLY THE ABOVE FORMAT. EXAMPLE: buy_crypto_price(\"ETHBTC\", 0.1). DO NOT SAY ANYTHING ELSE.\n",
        "ALSO IN THE AMOUNT FIELD, USE THE UNIT SYSTEM OF BITCOIN, NOT DOLLARS. ASSUME WE HAVE A BUDGET of UP TO $100 WORTH OF BITCOIN PER TRADE for 24 hours.\n",
        " ADD THE ACRONYM \"BTC\" AT THE END OF THE CRYPTO TICKER.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "openai.api_key = \"YOUR KEY\"\n",
        "\n",
        "# Feed the prompt to the AI\n",
        "response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature = 0.2,\n",
        "    )\n",
        "\n",
        "res = response.choices[0].message[\"content\"]\n",
        "res = res.replace(\"\\\\\", \"\")\n",
        "print(textwrap.fill(str(res), width=50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBt21IUAXgg0",
        "outputId": "1a873017-917a-41bb-fc74-db8d67db5abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sell_crypto_price(\"BTCUSD\", 0.003)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Prediction"
      ],
      "metadata": {
        "id": "dVF24mOUgEP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_embedding = openai.Embedding.create(\n",
        "    input=[\n",
        "        info_str\n",
        "    ], engine=\"text-embedding-ada-002\"\n",
        ")\n",
        "vector = prediction_embedding[\"data\"][0][\"embedding\"]\n",
        "pinecone_vectors = []\n",
        "\n",
        "\n",
        "pinecone_vectors.append((str(int(biggest_id)+1), vector))\n",
        "index.upsert(vectors=pinecone_vectors)\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ-WGJM7gHpE",
        "outputId": "a82523a8-5ec8-4375-9f02-000d6039301c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 6}},\n",
              " 'total_vector_count': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 - Trade"
      ],
      "metadata": {
        "id": "Si92S6n2XiUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rest_api = tradeapi.REST('YOUR_KEY', 'YOUR_OTHER_KEY','https://paper-api.alpaca.markets')\n",
        "\n",
        "def buy_crypto_price(symbol, amount):\n",
        "  rest_api.submit_order(symbol=symbol, qty=amount , type=\"market\", side=\"buy\", time_in_force=\"gtc\")\n",
        "\n",
        "def buy_crypto_limit(symbol, amount, limit):\n",
        "  rest_api.submit_order(symbol=symbol, qty=amount , type=\"limit\", side=\"buy\", time_in_force=\"gtc\", limit_price=limit)\n",
        "\n",
        "def sell_crypto_price(symbol, amount):\n",
        "  rest_api.submit_order(symbol=symbol, qty=amount , type=\"market\", side=\"sell\", time_in_force=\"gtc\")\n",
        "\n",
        "def sell_crypto_limit(symbol, amount, limit):\n",
        "  rest_api.submit_order(symbol=symbol, qty=amount , type=\"limit\", side=\"sell\", time_in_force=\"gtc\", limit_price=limit)"
      ],
      "metadata": {
        "id": "2EJoONP1XmYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)\n",
        "def execute_response(response):\n",
        "    match = re.match(r'(\\w+)\\((.*?)\\)', response)\n",
        "    if match:\n",
        "        command = match.group(1)\n",
        "        args = [arg.strip().strip('\\\"') for arg in match.group(2).split(',')]  # remove surrounding quotation marks\n",
        "        if len(args) == 1:\n",
        "          print(\"Doing nothing...\")\n",
        "          return\n",
        "        command_map = {\n",
        "            \"buy_crypto_price\": buy_crypto_price,\n",
        "            \"buy_crypto_limit\": buy_crypto_limit,\n",
        "            \"sell_crypto_price\": sell_crypto_price,\n",
        "            \"sell_crypto_limit\": sell_crypto_limit,\n",
        "            \"do_nothing\": lambda: None  # no action needed\n",
        "        }\n",
        "        function_to_execute = command_map.get(command)  # retrieves the function from command_map dictionary\n",
        "        if function_to_execute:\n",
        "            print(f\"Executing command {function_to_execute} with args {args} in 5 seconds.\")\n",
        "            time.sleep(5)\n",
        "            function_to_execute(*args)  # executes the function with its arguments\n",
        "        else:\n",
        "            print(\"Invalid command:\", command)\n",
        "    else:\n",
        "        print(\"Invalid response, retrying:\", response)\n",
        "        time.sleep(10)\n",
        "        execute_response(get_trade_advice())\n",
        "\n",
        "\n",
        "execute_response(res)\n",
        "print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bn8aAw4XpKP",
        "outputId": "0fd49349-76e0-4463-e8f8-c55239325859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sell_crypto_price(\"BTCUSD\", 0.003)\n",
            "so here sell_crypto_price(\"BTCUSD\", 0.003)\n",
            "Executing command <function sell_crypto_price at 0x7f9c973869e0> with args ['BTCUSD', '0.003'] in 5 seconds.\n",
            "done\n"
          ]
        }
      ]
    }
  ]
}